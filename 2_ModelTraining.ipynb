{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "import pickle as pkl\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, roc_auc_score, f1_score, r2_score\n",
    "from datetime import timedelta\n",
    "import time\n",
    "import csv\n",
    "from sklearnex import patch_sklearn\n",
    "patch_sklearn()\n",
    "\n",
    "X_train = pkl.load(open('CleanDataset/X_train.pkl', 'rb'))\n",
    "y_train = pkl.load(open('CleanDataset/y_train.pkl', 'rb'))\n",
    "\n",
    "def test_model(model, X_train=X_train, y_train=y_train):\n",
    "    cv = KFold(n_splits = 4, shuffle=True, random_state=1)\n",
    "    acc = make_scorer(accuracy_score)\n",
    "    prc = make_scorer(precision_score)\n",
    "    rec = make_scorer(recall_score)\n",
    "    auc = make_scorer(roc_auc_score)\n",
    "    f1 = make_scorer(f1_score)\n",
    "    r2 = make_scorer(r2_score)\n",
    "\n",
    "    acc_val_score = cross_val_score(model, X_train, y_train, cv=cv, scoring=acc)\n",
    "    prc_val_score = cross_val_score(model, X_train, y_train, cv=cv, scoring=prc)\n",
    "    rec_val_score = cross_val_score(model, X_train, y_train, cv=cv, scoring=rec)\n",
    "    auc_val_score = cross_val_score(model, X_train, y_train, cv=cv, scoring=auc)\n",
    "    f1_val_score = cross_val_score(model, X_train, y_train, cv=cv, scoring =f1)\n",
    "    r2_val_score = cross_val_score(model, X_train, y_train, cv=cv, scoring=r2)\n",
    "    score = [acc_val_score.mean(), prc_val_score.mean(), rec_val_score.mean(), auc_val_score.mean(),\\\n",
    "             f1_val_score.mean(), r2_val_score.mean()]\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_csv(model_name, result, duration):\n",
    "    msg = [{'Model':f'{model_name}','Training time': f\"{duration}\",'Accuracy': f\"{round(result[0],4)*100}\", \\\n",
    "    'Precision': f'{round(result[1],4)*100}', 'Recall': f'{round(result[2],4)*100}', 'AUC': f'{round(result[3],4)*100}',\\\n",
    "    'F1': f'{round(result[4],4)*100}', 'R2': f'{round(result[5],3)}'}]\n",
    "\n",
    "    with open('record_result', 'a', newline='\\n') as csvfile:\n",
    "        fieldnames = ['Model', 'Training time', 'Accuracy', 'Precision', 'Recall', 'AUC', 'F1', 'R2']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writerows(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.8948647 ,  0.50373453, -0.59467758, ..., -1.55668752,\n",
       "         0.42370398,  0.16459136],\n",
       "       [-1.11748736, -1.16937726,  1.6815835 , ..., -1.55668752,\n",
       "         0.42370398,  0.16459136],\n",
       "       [ 0.8948647 ,  0.92201247, -0.59467758, ...,  0.64238968,\n",
       "        -1.34400414,  0.16459136],\n",
       "       ...,\n",
       "       [ 0.8948647 ,  1.41000341, -0.59467758, ...,  0.64238968,\n",
       "        -1.34400414, -6.07565293],\n",
       "       [-1.11748736, -0.33282137, -0.59467758, ...,  0.64238968,\n",
       "        -0.46015008,  0.16459136],\n",
       "       [ 0.8948647 ,  0.01574359, -0.59467758, ...,  0.64238968,\n",
       "        -0.46015008,  0.16459136]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7844819563815715, 0.7070601203312665, 0.9714277227548006, 0.7844817205135293, 0.8184229395178693, 0.13791040809997762]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression as LogReg\n",
    "LR = LogReg()\n",
    "start = time.perf_counter()\n",
    "ResultLogReg = test_model(LR)\n",
    "print(ResultLogReg)\n",
    "duration = timedelta(seconds=time.perf_counter()-start)\n",
    "\n",
    "insert_csv('Logistic Regression', ResultLogReg, duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8133371221940827, 0.7567761887540185, 0.923143471889857, 0.8131861205247757, 0.8316842208990151, 0.25316722483054677]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=200)\n",
    "start = time.perf_counter()\n",
    "ResultRF = test_model(clf)\n",
    "print(ResultRF)\n",
    "duration = timedelta(seconds=time.perf_counter()-start)\n",
    "\n",
    "insert_csv('Random Forest', ResultRF, duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8057294886367412, 0.7460462352778905, 0.9270041284841634, 0.8057287023792248, 0.8267378479143874, 0.22290225319865128]\n"
     ]
    }
   ],
   "source": [
    "import xgboost\n",
    "xgb = xgboost.XGBClassifier()\n",
    "start = time.perf_counter()\n",
    "ResultXGB = test_model(xgb)\n",
    "print(ResultXGB)\n",
    "duration = timedelta(seconds=time.perf_counter()-start)\n",
    "\n",
    "insert_csv('XGBoost', ResultXGB, duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc = SVC()\n",
    "start = time.perf_counter()\n",
    "ResultSVM = test_model(svc)\n",
    "print(ResultSVM)\n",
    "duration = timedelta(seconds=time.perf_counter()-start)\n",
    "\n",
    "insert_csv('SVM', ResultSVM, duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sklearn MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(random_state=None, max_iter=75, activation='logistic', learning_rate='adaptive', early_stopping=True)\n",
    "start = time.perf_counter()\n",
    "ResultMLP = test_model(mlp)\n",
    "print(ResultMLP)\n",
    "duration = timedelta(seconds=time.perf_counter()-start)\n",
    "\n",
    "insert_csv('MLP', ResultMLP, duration)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
